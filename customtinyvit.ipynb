{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "C_T__6vLjSG8"
      },
      "outputs": [],
      "source": [
        "#!pip install onnx onnxruntime tf2onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAJ3KtT4UVfd",
        "outputId": "d0ee46bf-5bf6-4ad2-9b1c-188660b70d87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.19.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers as L\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HwIflR51UXCR"
      },
      "outputs": [],
      "source": [
        "class CustomLayerNorm(L.Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.eps = eps\n",
        "        self.gamma = None\n",
        "        self.beta = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        dim = int(input_shape[-1])\n",
        "        self.gamma = self.add_weight(\n",
        "            name=\"gamma\", shape=(dim,), initializer=\"ones\", trainable=True\n",
        "        )\n",
        "        self.beta = self.add_weight(\n",
        "            name=\"beta\", shape=(dim,), initializer=\"zeros\", trainable=True\n",
        "        )\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        mean = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
        "        var  = tf.reduce_mean(tf.square(x - mean), axis=-1, keepdims=True)\n",
        "        xhat = (x - mean) / tf.sqrt(var + self.eps)\n",
        "        return xhat * self.gamma + self.beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e2r77I_7UaK-"
      },
      "outputs": [],
      "source": [
        "class RMSNorm(L.Layer):\n",
        "    def __init__(self, eps=1e-6, use_bias=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.eps = eps\n",
        "        self.use_bias = use_bias\n",
        "        self.gamma = None\n",
        "        self.beta = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        dim = int(input_shape[-1])\n",
        "        self.gamma = self.add_weight(\n",
        "            name=\"gamma\", shape=(dim,), initializer=\"ones\", trainable=True\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            self.beta = self.add_weight(\n",
        "                name=\"beta\", shape=(dim,), initializer=\"zeros\", trainable=True\n",
        "            )\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        rms = tf.sqrt(tf.reduce_mean(tf.square(x), axis=-1, keepdims=True) + self.eps)\n",
        "        y = (x / rms) * self.gamma\n",
        "        if self.use_bias:\n",
        "            y = y + self.beta\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yuqGks6DOabu"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ----------------------\n",
        "# 기본 블록: Transformer Encoder\n",
        "# ----------------------\n",
        "class TransformerEncoder(L.Layer):\n",
        "    def __init__(self, dim, num_heads, mlp_dim, dropout=0.1, use_layernorm=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        #self.norm1 = L.LayerNormalization(epsilon=1e-6)\n",
        "        if use_layernorm:\n",
        "          self.norm1 = CustomLayerNorm(eps=1e-6)\n",
        "        else:\n",
        "          self.norm1 = RMSNorm(eps=1e-6)\n",
        "\n",
        "        self.attn = L.MultiHeadAttention(num_heads=num_heads, key_dim=dim//num_heads, dropout=dropout)\n",
        "        self.drop1 = L.Dropout(dropout)\n",
        "\n",
        "        if use_layernorm:\n",
        "          self.norm2 = CustomLayerNorm(eps=1e-6)\n",
        "        else:\n",
        "          self.norm2 = RMSNorm(eps=1e-6)\n",
        "        self.mlp   = tf.keras.Sequential([\n",
        "            L.Dense(mlp_dim, activation=tf.keras.activations.relu),\n",
        "            L.Dropout(dropout),\n",
        "            L.Dense(dim),\n",
        "            L.Dropout(dropout)\n",
        "        ])\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        # Self-Attention + Residual\n",
        "        h = self.norm1(x)\n",
        "        h = self.attn(h, h, training=training)\n",
        "        x = x + self.drop1(h, training=training)\n",
        "        # MLP + Residual\n",
        "        h = self.norm2(x)\n",
        "        h = self.mlp(h, training=training)\n",
        "        return x + h\n",
        "\n",
        "# ----------------------\n",
        "# ViT 모델 생성 함수 (간단 버전)\n",
        "# ----------------------\n",
        "def build_vit(\n",
        "    image_size=224,          # 입력 이미지 한 변 크기\n",
        "    patch_size=16,           # 패치 한 변 크기\n",
        "    num_classes=10,          # 클래스 수\n",
        "    dim=192,                 # 토큰 임베딩 차원\n",
        "    depth=6,                 # Transformer layer 개수\n",
        "    heads=3,                 # Multi-Head 수\n",
        "    mlp_dim=384,             # MLP 내부 차원\n",
        "    dropout=0.1,\n",
        "    use_layernorm=False\n",
        "):\n",
        "    assert image_size % patch_size == 0, \"image_size는 patch_size로 나누어 떨어져야 합니다.\"\n",
        "    num_patches = (image_size // patch_size) ** 2\n",
        "\n",
        "    inputs = L.Input(shape=(image_size, image_size, 3),batch_size=1)\n",
        "\n",
        "    # 1) 패치 임베딩: Conv로 패치 분할 + 선형 투영\n",
        "    x = L.Conv2D(\n",
        "        filters=dim, kernel_size=patch_size, strides=patch_size,\n",
        "        padding=\"valid\", name=\"patch_embedding\"\n",
        "    )(inputs)                           # [B, H/ps, W/ps, dim]\n",
        "    x = L.Reshape((num_patches, dim))(x)  # [B, N, dim]\n",
        "\n",
        "    # 2) 위치 임베딩(learnable)\n",
        "    pos_embed = self_positional_embedding(num_patches, dim, name=\"positional_embedding\")\n",
        "    x = x + pos_embed\n",
        "\n",
        "    # 3) Transformer Encoder stack\n",
        "    for i in range(depth):\n",
        "        x = TransformerEncoder(dim=dim, num_heads=heads, mlp_dim=mlp_dim, dropout=dropout,use_layernorm=use_layernorm, name=f\"encoder_{i}\")(x)\n",
        "\n",
        "    # 4) 분류 헤드: GAP over tokens -> Dense\n",
        "    #x = L.LayerNormalization(epsilon=1e-6)(x)\n",
        "    if use_layernorm:\n",
        "      x = CustomLayerNorm(eps=1e-6)(x)\n",
        "    else:\n",
        "      x = RMSNorm(eps=1e-6)(x)\n",
        "    x = L.GlobalAveragePooling1D()(x)\n",
        "    x = L.Dropout(dropout)(x)\n",
        "    outputs = L.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return tf.keras.Model(inputs, outputs, name=\"TinyViT\")\n",
        "\n",
        "def self_positional_embedding(num_patches, dim, name=\"positional_embedding\"):\n",
        "    # [1, N, dim] 학습 가능한 위치 임베딩\n",
        "    pe = tf.Variable(\n",
        "        initial_value=tf.random.normal([1, num_patches, dim]) * 0.02,\n",
        "        trainable=True, name=name, dtype=tf.float32\n",
        "    )\n",
        "    # Keras Functional 호환을 위해 Lambda로 감싼 텐서를 반환\n",
        "    return L.Lambda(lambda _: pe)(tf.zeros((1, num_patches, dim)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PJdUejsPHZx",
        "outputId": "4042f457-1072-41b6-da18-34f558e47042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Colab cache for faster access to the 'flowers-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/flowers-dataset\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"imsparsh/flowers-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_ywuJLK2OpEM"
      },
      "outputs": [],
      "source": [
        "# ----------------------\n",
        "# 샘플 사용법\n",
        "# ----------------------\n",
        "def get_model(use_layernorm):\n",
        "    # 하이퍼파라미터\n",
        "    IMG = 224\n",
        "    PATCH = 16\n",
        "    NCLASS = 5\n",
        "\n",
        "    model = build_vit(\n",
        "        image_size=IMG, patch_size=PATCH,\n",
        "        num_classes=NCLASS, dim=128, depth=5, heads=5, mlp_dim=256, dropout=0.1,use_layernorm=use_layernorm\n",
        "    )\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIUtbqnBXX1m"
      },
      "source": [
        "# with RMSNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "cyFUdpiiPeJV",
        "outputId": "cfd2afd4-5432-44e8-c3ee-e4e697cc9944"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TinyViT\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"TinyViT\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ patch_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">130,679</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">130,679</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">130,679</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">130,679</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">130,679</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rms_norm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RMSNorm</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ patch_embedding (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,432\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_0 (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m130,679\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_1 (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m130,679\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_2 (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m130,679\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_3 (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m130,679\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_4 (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m130,679\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rms_norm_10 (\u001b[38;5;33mRMSNorm\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │           \u001b[38;5;34m645\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">752,600</span> (2.87 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m752,600\u001b[0m (2.87 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">752,600</span> (2.87 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m752,600\u001b[0m (2.87 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2746 files belonging to 5 classes.\n",
            "Epoch 1/2\n",
            "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 118ms/step - accuracy: 0.2358 - loss: 1.7981\n",
            "Epoch 2/2\n",
            "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4775 - loss: 1.2332\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c642c05c0b0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def preprocess(x, y):\n",
        "      x = tf.image.resize(x, (IMG, IMG))\n",
        "      x = tf.cast(x, tf.float32) / 255.0\n",
        "      return x, y\n",
        "\n",
        "model = get_model(use_layernorm=False)\n",
        "IMG=224\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "\"/kaggle/input/flowers-dataset/train\",\n",
        "    image_size=(IMG,IMG),\n",
        "    batch_size=8\n",
        ")\n",
        "\n",
        "normalization_layer = L.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "model.fit(train_ds, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEtY17s4kTjH",
        "outputId": "649047e8-0df4-4b7f-d278-bd68d3684498"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('tinytvit.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZmDcwv7d5hw",
        "outputId": "eb7ec9f9-6ac8-42fe-b9b0-cd21669f4d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at 'tinyvit'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136769733092624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733093776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733094160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733099152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733098960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733098384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733098576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733099344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733098000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733098768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684194128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684193552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684195856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684193936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684195280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684196240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684196048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733098192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733094928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684197776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684198544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684198352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684198928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684197008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684197392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684194320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684200080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684198160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684199504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684200464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684200272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684193744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684201424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684201616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684202384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684202192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684202768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684201040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684195664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684198736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684203920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684199888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684203344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684204304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684204112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684202576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684201232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684205072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684205840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684205648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684206224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684202960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684202000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684204880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684207376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684197968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684206800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684207760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684207568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684201808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684206416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684208528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684205264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684208912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684207184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684209104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684203728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684208720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684206032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684208336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769676870672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769676871056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769676871248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684205456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769676870288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769676871824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ],
      "source": [
        "model.export('tinyvit')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7LTm_dWiS71U"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "def load_image_as_float(path, img_size):\n",
        "    # RGB 보장, 리사이즈, [0,1] 스케일\n",
        "    with Image.open(path) as im:\n",
        "        im = im.convert(\"RGB\")\n",
        "        im = im.resize((img_size, img_size), Image.BILINEAR)\n",
        "        arr = np.asarray(im, dtype=np.float32) / 255.0\n",
        "    return arr  # (H, W, 3) float32\n",
        "def representative_data_gen():\n",
        "    # test 폴더에서 확장자별로 수집\n",
        "    exts = (\"*.jpg\")\n",
        "    img_paths = []\n",
        "    for ext in exts:\n",
        "        img_paths.extend(glob.glob(os.path.join('/kaggle/input/flowers-dataset/test', ext)))\n",
        "\n",
        "    if not img_paths:\n",
        "        raise FileNotFoundError(f\"No images found under: {'/kaggle/input/flowers-dataset/test'}\")\n",
        "\n",
        "\n",
        "    for p in img_paths[:200]:\n",
        "        x = load_image_as_float(p, IMG)      # (H,W,3) float32 in [0,1]\n",
        "        x = np.expand_dims(x, 0)             # (1,H,W,3)\n",
        "        # TFLite는 'list of input tensors'로 받습니다.\n",
        "        yield [x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RbhTCBD3keQy"
      },
      "outputs": [],
      "source": [
        "# ====== 3) INT8(완전 정수) 양자화 ======\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "# 완전 정수 경로: 모든 연산, 입출력까지 int8\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type  = tf.uint8\n",
        "converter.inference_output_type = tf.float32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s07gY8nxk1RT",
        "outputId": "4a4ad14e-a7c1-4644-bf35-6765dfa57a9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmplls56emj'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 224, 224, 3), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 5), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136769733092624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733093776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733094160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733099152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733098960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733098384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733098576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733099344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733098000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733098768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684194128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684193552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684195856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684193936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684195280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684196240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684196048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733098192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769733094928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684197776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684198544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684198352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684198928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684197008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684197392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684194320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684200080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684198160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684199504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684200464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684200272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684193744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684201424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684201616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684202384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684202192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684202768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684201040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684195664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684198736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684203920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684199888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684203344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684204304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684204112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684202576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684201232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684205072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684205840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684205648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684206224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684202960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684202000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684204880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684207376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684197968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684206800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684207760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684207568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684201808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684206416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684208528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684205264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684208912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684207184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684209104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684203728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684208720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684206032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684208336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769676870672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769676871056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769676871248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769684205456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769676870288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136769676871824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tflite_model = converter.convert()\n",
        "with open(\"custom_vit_int8.tflite\", \"wb\") as f:\n",
        "        f.write(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
